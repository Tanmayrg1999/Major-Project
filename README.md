# Major-Project

## ABSTRACT

Web site personalization is defined as the process of customizing the web-content
and structure of a Web site to the specific and individual needs of each user taking advantage of the user’s navigational behavior. The main goal of personalization
is delivering the content and thus matching the functionality or interests that user
needs, with no effort from the targeted users. Personalization may emphasize user’s
particular information, grant or restrict access to certain tools, or simplify transactions and processes by remembering information about a user.
On a traveling web-site, a user may see advertisements, promotions and specials for
locations they have visited before or recently searched for. On an internet, personalization could remove access to a tool intended only for certain employees. In an
application, personalization might study user past searches so as to enable quick access of information that might be of interest for future to the users. In none of these
instances do users need to take any action to make these changes: the system makes
the call based on the identity of the user.The purpose of this project is to provide
personalized experience to the user while searching data. 

Users, when searched data
will inform about its relevance as a feedback and according a customized search, will
be provided to the users. In our project we are going to implement a personalization
system in which user will browse the content according to their requirement then
from the searched information they will provide feedback for the relevance of that
where the data will be processed through various stages as editorial planning, content
reusing, navigation and content hierarchy

##  INTRODUCTION

Web site personalization is defined as the process of customizing the web-content
and structure of a Web site to the specific and individual needs of each user taking advantage of the user’s navigational behavior. The main goal of personalization
is delivering the content and thus matching the functionality or interests that user
needs, with no effort from the targeted users. Personalization may emphasize user’s
particular information, grant or restrict access to certain tools, or simplify transactions and processes by remembering information about a user.
On a traveling web-site, a user may see advertisements, promotions and specials for
locations they have visited before or recently searched for. On an internet, personalization could remove access to a tool intended only for certain employees. In an
application, personalization might study user past searches so as to enable quick access of information that might be of interest for future to the users. In none of these
instances do users need to take any action to make these changes: the system makes
the call based on the identity of the user.The purpose of this project is to provide
personalized experience to the user while searching data. Users, when searched data
will inform about its relevance as a feedback and according a customized search, will
be provided to the users. In our project we are going to implement a personalization
system in which user will browse the content according to their requirement then
from the searched information they will provide feedback for the relevance of that
where the data will be processed through various stages as editorial planning, content
reusing, navigation and content hierarchy.

## PURPOSE
The purpose of this project is to provide personalized experience to the user while
searching data. Users when searched data will inform about its relevance as a feed-back and according a customized search will be provided to the users.

## PROBLEM STATEMENT
To find useful and relevant information based on the keyword typed and the user’s
interest which is found out using different methods of personalization of information
and algorithms.

## SCOPE
In our project we are going to implement a personalization system in which user will
browse the content according to their requirement then from the searched information
they will provide feedback for the relevance of that where the data will be processed
through various stages as editorial planning, content reusing ,navigation and content
hierarchy, Users flow and calls to action, content structure Taxonomy and Metadata
,Content development and production .This will result in the customized data to the
user.

## OBJECTIVES
The main objective of this project is to provide personalized experience to the user
while searching data. Users when searched data will inform about its relevance as a
feedback and according a customized search will be provided to the users.Also we will
try to find useful and relevant information based on the keyword typed and the user’s
interest which is found out using different methods of personalization of information
and algorithms. We’ll try to save a whole bunch of time working over the internet
and provide more Relevant data Recommendations.It focuses on consistency among
2the website users and every user gets a personalized experience of the website but at
the same time we cannot get it right every time that’s what’s going on in the mind
of the user.It comes with great customer service and satisfaction although it comes
at its own cost for the users.

## THEORY AND RELEVANCE
1. Web Scraping:

Web scraping is the process of collection of structured web data in an structured fashion. It’s also called web data extraction. There are many use cases of web scraping
which include price intelligence, monitoring new, price monitoring, generation of lead
and market research among many others. Web scraping a web page involves extracting data and results from it that are relevant. Therefore, web crawling is one of the
main component of web scraping, so as to extract pages for later processing. Once
fetched, then extraction can take place. These contents of pages may be searched,
parsed, reformatted, its data copied into a spreadsheet etc. Web scrapers typically
extracts relevant data out of a page, to make use of it for another purpose by studying data. This is an automatic version of gathering well-structured data from web
pages.In other terms it is said to be web-data extraction. Web scraping a web page
implies fetching it, and extracting data from it. Fetching is actually the downloading
of a page. Hence, web crawling is a major component of web scraping, to fetch pages
for further processing. Once after fetching the data, then data extraction can take
place . Web Crawling actually consists of a crawler that automatically searches and
explores content on the web. Crawlers are fundamentally programmed for repetitive
steps and actions such that web browsing and searching gets automated. Some websites contain a massive amount of invaluable data. It’s a very tedious job to manually
8extract this huge amount of data. Web Scraping extracts this huge amount of data
and then exports it to a format that is more convenient for the user ( For Eg. Excel,
pdf etc).

2. Web-Usage Mining :

Web usage mining is the application of data mining techniques to discover interesting usage pattern from the Web data in order to study and better satisfy the needs
of Web-based applications. Usage data captures the identity or origin of Web users
along with their browsing behavior at a Web site.Web usage mining is a subcategory
of data mining which is used for recognizing usage patterns and trends from web
data. This is a combination of different applied techniques, to unravel informative
usage trends from data taken over the internet. Web usage mining understands the
requirements and needs of web based applications and It is then analyzed, understood and is then fed to web based applications. This type of data captures the
identity or emergence of Web users along with their behavior of how they browse
and browsing history, at browser level as well as website level
Web usage mining can be classified depending on the kind of data-usage considered:

   a. Web server data: The user information are collected by the Web server.The typical user data includes IP address of site, page data etc.

   b. Application server data: Many Commercial application servers have significant
functionality so as to enable applications to be built on top of them with minimal
effort. A key feature of this is the ability to understand various kinds of business
events and thus log them in application server data.

   c. Application level data: Many new kinds of events and actions can be defined in an
application, and thus logging can be turned manually on for them thus generating
past searches of these specially defined actions. Many back-end application requires
a combo of one or more of these techniques applied.

3. Web personalization :

Web Personalisation or Personalisation of information is a web mining technique
which helps the customers to find relevant information to the searches they make on
the internet. The main focus of this project is on providing the users the provision
of bettering their web searches and personalizing according to their experience and
also help them in personalizing the information with some external help such as
recommendation system, search feedback, pages indexing etc.
After studying and analyzing many paper and articles on web, we found that the
main problem in the system is :

   a. Optimized Landing Pages
   
   b. More Relevant Content Recommendations
   
   c. Increase in User Engagement on the Website.
   
   d. Unsatisfactory Search Results
   
   e. Inefficient methods of getting useful information
   
   f. Reduce the time required for finding useful results

## System Designing/Modeling

### Module 1 - 
Collection of data ( by web scraping ) - Web Scraping (also termed Screen
Scraping, Web Data Extraction, Web Harvesting etc.) is a technique employed to
extract large amounts of data from websites

1. We can gather information depending on three approaches:

   a. Information gathering approach(whether implicit/explicit)

   b. Type of information(users and their usage behavior when interacting with the system)

   c. Source of information(gathered at the server-side or at the client-side)

2. In the implicit method, information is gathered unobtrusively, without any effort
from the user.

3. In the explicit method, the users themselves have to explicitly supply information
to the system, whether positive or negative.

### Module 2 -
Analysing and pre-processing the data -

1. Finding the missing values.

2. Finding out inconsistent data.

3. Dealing with Duplicate values.

4. Data Transformation

5. Data Reduction

### Module 3 - 
Personalization in PIR systems is generally performed by adapting the
query and/or the results. Query adaptation: Query adaptation attempts to expand
the terms of the user’s query with other terms, with the aim of retrieving more rel12evant results.

1. processing the user model

2. processing aggregate usage information

3. pseudo-relevance feedback

4. global analysis

5. Explicit relevance feedback

6. interactive query expansion

### Module 4 - 
Applying the suitable and most appropriate algorithm so that we could
get more relevant and personalized results.

Algorithm Used

1. Pseudo -Relevance Feedback:
Pseudo relevance feedback , also known as blind relevance feedback , provides a
method for automatic local analysis. It automates the manual part of relevance
feedback, so that the user gets improved retrieval performance without an extended
interaction. The method is to do normal retrieval to find an initial set of most relevant documents, to then assume that the top ranked documents are relevant, and
finally to do relevance feedback as before under this assumption.. The idea behind
relevance feedback is to take the results that are initially returned from a given query,
to gather user feedback, and to use information about whether or not those results
are relevant to perform a new query. We can usefully distinguish between three types
of feedback: explicit feedback, implicit feedback, and blind or ”pseudo” feedback.

2. Page Rank Algorithm:
PageRank (PR) is an algorithm used by Google Search to rank websites in their
search engine results. PageRank is a way of measuring the importance of website
pages. PageRank works by counting the number and quality of links to a page to
determine a rough estimate of how important the website is. The underlying assumption is that more important websites are likely to receive more links from other
websites.
